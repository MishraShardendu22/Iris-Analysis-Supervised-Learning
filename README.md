# Iris Analysis Supervised Learning

A comprehensive machine learning project implementing various supervised learning algorithms to classify iris flowers based on their physical characteristics.

## ğŸ“‹ Table of Contents

- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Features](#features)
- [Algorithms Implemented](#algorithms-implemented)
- [Usage](#usage)
- [Results](#results)
- [Model Evaluation](#model-evaluation)
- [Dependencies](#dependencies)
- [Author](#author)
- [License](#license)

## ğŸ¯ Project Overview

This project focuses on building and evaluating multiple supervised learning models to classify iris flowers into three species:
- **Setosa**
- **Versicolor**
- **Virginica**

The project demonstrates the complete machine learning pipeline including data exploration, preprocessing, model training, evaluation, and comparison of different algorithms.

## ğŸ“Š Dataset

The project uses the famous **Iris Dataset**, one of the most well-known datasets in machine learning and statistics.

### Dataset Characteristics:
- **Number of Samples**: 150 instances
- **Number of Features**: 4 numerical features
- **Target Classes**: 3 (Iris Setosa, Iris Versicolor, Iris Virginica)
- **Missing Values**: None

### Features:
1. **Sepal Length** (cm) - Length of the flower's sepal
2. **Sepal Width** (cm) - Width of the flower's sepal
3. **Petal Length** (cm) - Length of the flower's petal
4. **Petal Width** (cm) - Width of the flower's petal

## ğŸš€ Installation

### Prerequisites
- Python 3.7 or higher
- pip (Python package installer)

### Clone the Repository
```bash
git clone https://github.com/MishraShardendu22/Iris-Analysis-Supervised-Learning.git
cd Iris-Analysis-Supervised-Learning
```

### Install Required Packages
```bash
pip install -r requirements.txt
```

Or manually install dependencies:
```bash
pip install numpy pandas scikit-learn matplotlib seaborn jupyter
```

## ğŸ“ Project Structure

```
Iris-Analysis-Supervised-Learning/
â”œâ”€â”€ README.md                          # Project documentation
â”œâ”€â”€ requirements.txt                   # Project dependencies
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ iris_analysis.ipynb           # Jupyter notebook with analysis
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py                # Data loading utilities
â”‚   â”œâ”€â”€ preprocessing.py              # Data preprocessing functions
â”‚   â”œâ”€â”€ models.py                     # Model implementation
â”‚   â””â”€â”€ evaluation.py                 # Evaluation metrics
â”œâ”€â”€ data/
â”‚   â””â”€â”€ iris.csv                      # Iris dataset
â””â”€â”€ results/
    â”œâ”€â”€ model_comparison.png          # Model performance visualization
    â””â”€â”€ confusion_matrices.png        # Confusion matrices
```

## âœ¨ Features

- **Exploratory Data Analysis (EDA)**: Comprehensive statistical analysis and visualization of the iris dataset
- **Data Preprocessing**: Standardization and normalization of features
- **Multiple Algorithms**: Implementation of various supervised learning algorithms
- **Cross-Validation**: Robust evaluation using k-fold cross-validation
- **Hyperparameter Tuning**: Grid search for optimal model parameters
- **Visualization**: Comprehensive plots for feature relationships and model performance
- **Model Comparison**: Side-by-side comparison of different algorithms

## ğŸ¤– Algorithms Implemented

This project implements and evaluates the following supervised learning algorithms:

1. **Logistic Regression**
   - Binary and multiclass classification
   - Regularization: L1, L2
   - Fast training and inference

2. **Decision Trees**
   - Information gain and Gini impurity criteria
   - Depth control to prevent overfitting
   - Feature importance analysis

3. **Random Forest**
   - Ensemble method for improved accuracy
   - Feature importance evaluation
   - Reduced overfitting through bootstrapping

4. **Support Vector Machines (SVM)**
   - Linear and non-linear kernels (RBF, Polynomial)
   - Optimal hyperplane separation
   - Robust classification

5. **K-Nearest Neighbors (KNN)**
   - Distance-based classification
   - Optimal k-value selection
   - Simple yet effective baseline

6. **Gradient Boosting**
   - Sequential ensemble learning
   - Iterative error correction
   - High accuracy potential

7. **Neural Networks**
   - Multi-layer perceptron architecture
   - Backpropagation training
   - Non-linear decision boundaries

## ğŸ’» Usage

### Basic Usage

```python
from src.data_loader import load_iris_data
from src.preprocessing import preprocess_data
from src.models import train_model
from src.evaluation import evaluate_model

# Load data
X, y = load_iris_data()

# Preprocess data
X_train, X_test, y_train, y_test = preprocess_data(X, y)

# Train model
model = train_model(X_train, y_train, algorithm='random_forest')

# Evaluate model
results = evaluate_model(model, X_test, y_test)
print(results)
```

### Running the Jupyter Notebook

```bash
jupyter notebook notebooks/iris_analysis.ipynb
```

### Training All Models

```python
from src.models import train_all_models

models = train_all_models(X_train, y_train)
```

## ğŸ“ˆ Results

The project evaluates models using multiple metrics:

### Evaluation Metrics
- **Accuracy**: Overall correct predictions
- **Precision**: True positives / (True positives + False positives)
- **Recall**: True positives / (True positives + False negatives)
- **F1-Score**: Harmonic mean of precision and recall
- **Confusion Matrix**: Detailed classification breakdown
- **ROC-AUC Score**: Area under the Receiver Operating Characteristic curve

### Expected Performance
Most models achieve **95%+ accuracy** on the iris dataset due to its well-separated classes and clear feature relationships.

## ğŸ” Model Evaluation

### Cross-Validation
- **Method**: 5-fold and 10-fold cross-validation
- **Purpose**: Ensure model generalization and stability

### Hyperparameter Tuning
- **Grid Search**: Exhaustive search over parameter ranges
- **Random Search**: Efficient parameter space exploration

### Comparison Metrics
Models are compared based on:
- Training time
- Inference time
- Accuracy and F1-Score
- Memory usage
- Interpretability

## ğŸ“¦ Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| numpy | â‰¥1.19.0 | Numerical computing |
| pandas | â‰¥1.1.0 | Data manipulation |
| scikit-learn | â‰¥0.24.0 | Machine learning algorithms |
| matplotlib | â‰¥3.3.0 | Data visualization |
| seaborn | â‰¥0.11.0 | Statistical visualization |
| jupyter | â‰¥1.0.0 | Interactive notebooks |

## ğŸ‘¨â€ğŸ’» Author

**Shardendu Mishra**
- GitHub: [@MishraShardendu22](https://github.com/MishraShardendu22)
- Project: [Iris-Analysis-Supervised-Learning](https://github.com/MishraShardendu22/Iris-Analysis-Supervised-Learning)

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ™ Acknowledgments

- The Iris dataset was collected by Edgar Anderson and popularized by Ronald Fisher
- Special thanks to the scikit-learn and pandas communities for excellent documentation

## ğŸ“¬ Contributing

Contributions are welcome! Please feel free to:
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## â“ FAQ

**Q: What is the best model for this dataset?**
A: Random Forest and SVM typically perform best, but the choice depends on your specific requirements (accuracy vs. interpretability).

**Q: Can I use this for other datasets?**
A: Yes! The code is modular and can be adapted for other classification problems with similar preprocessing adjustments.

**Q: How do I improve model accuracy?**
A: Try feature engineering, different algorithms, hyperparameter tuning, or ensemble methods.

**Q: Is the dataset imbalanced?**
A: No, the iris dataset has balanced classes with 50 samples per species.

## ğŸš¦ Getting Started

1. Clone the repository
2. Install dependencies: `pip install -r requirements.txt`
3. Run the Jupyter notebook: `jupyter notebook notebooks/iris_analysis.ipynb`
4. Explore the code and results
5. Modify and experiment with different models and parameters

---

**Last Updated**: January 7, 2026

For questions or suggestions, please open an issue on the [GitHub repository](https://github.com/MishraShardendu22/Iris-Analysis-Supervised-Learning/issues).
